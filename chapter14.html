<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>chapter14</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
  </style>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" type="text/javascript"></script>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<p>#Simple applicatons of decision theory.</p>
<p><span class="math inline">\(\leftarrow\)</span> <a href="./index.html">Back to Chapters</a></p>
<h3 id="comments-on-14.1-and-14.2">Comments on 14.1 and 14.2</h3>
<p>On p. 428 Jaynes seems to be describing a simple probabilistic graphical model (and is making some analogy between belief propagation in a PGM and Huygens principle).</p>
<p><span class="math inline">\(Y\)</span> — <span class="math inline">\(V\)</span> — <span class="math inline">\(D\)</span></p>
<p>Then <span class="math inline">\(V\)</span> screens <span class="math inline">\(D\)</span> from <span class="math inline">\(Y\)</span> and also screens <span class="math inline">\(Y\)</span> from <span class="math inline">\(D\)</span>.</p>
<p>See also <a href="http://ksvanhorn.com/bayes/jaynes/node16.html">this</a> on Kevin Van Horn’s page.</p>
<h3 id="comments-on-14.4">Comments on 14.4</h3>
<p>Small nitpick: There is a discrepancy between the caption of Fig 14.1 and the text (<span class="math inline">\(L_a=2, L_r=1\)</span> gives <span class="math inline">\(L_a=2L_r\)</span> and not <span class="math inline">\(L_a=(3/2)L_r\)</span>).</p>
<p>A key point seems to be that (in the example at hand) both the minimax and Neyman-Pearson decision rules are reproduced by a Bayesian decision rule with appropriate prior. It would be interesting to know how general this phenomenon is. I guess by Wald’s theorem one only needs to show that minimax/Neyman-Pearson is an dmissible decision rule, as Jaynes says: “Wald showed in great generality what we have just illustrated by one simple example”.</p>
</body>
</html>
